{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import torch.nn.functional as F \n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import numpy as np, os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt  \n",
        "import mlflow                   \n",
        "import mlflow.pytorch    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "tfm_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "tfm_val = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_TYPE = \"condition\" \n",
        "\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "DATA_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / DATASET_TYPE\n",
        "TRAIN_DIR = DATA_ROOT / \"train\"\n",
        "VAL_DIR   = DATA_ROOT / \"val\"\n",
        "\n",
        "print(f\"Using dataset: {DATASET_TYPE}\")\n",
        "print(f\"Train dir: {TRAIN_DIR}\")\n",
        "print(f\"Val dir:   {VAL_DIR}\")\n",
        "\n",
        "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=tfm_train)\n",
        "val_ds   = datasets.ImageFolder(VAL_DIR,   transform=tfm_val)\n",
        "num_classes = len(train_ds.classes)\n",
        "\n",
        "print(\"Classes:\", train_ds.classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Get the count for each class in the *training* set\n",
        "counts = np.bincount(train_ds.targets)\n",
        "print(f\"Training counts: {dict(zip(train_ds.classes, counts))}\")\n",
        "\n",
        "# Calculate weights (inversely proportional to class frequency)\n",
        "weight_for_0 = (1 / counts[0]) * (sum(counts) / num_classes)\n",
        "weight_for_1 = (1 / counts[1]) * (sum(counts) / num_classes)\n",
        "class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float32).to(device)\n",
        "print(f\"Using weights (for 'good', 'worn'): {class_weights.cpu().numpy()}\")\n",
        "# --- END NEW ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# 1. Freeze all parameters first\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# 2. Unfreeze the final block (layer4)\n",
        "for p in model.layer4.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "# 3. Replace the head \n",
        "in_feats = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(p=0.5), # a 50% dropout layer\n",
        "    nn.Linear(in_feats, num_classes)\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LEARNING_RATE_HEAD = 5e-4\n",
        "LEARNING_RATE_BODY = 1e-6\n",
        "\n",
        "opt = optim.AdamW([\n",
        "    {\"params\": model.layer4.parameters(), \"lr\": LEARNING_RATE_BODY},\n",
        "    {\"params\": model.fc.parameters(), \"lr\": LEARNING_RATE_HEAD}\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "# 2. Add weights to the loss function\n",
        "crit = nn.CrossEntropyLoss(weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for x,y in val_dl:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = crit(logits, y)\n",
        "            loss_sum += loss.item() * y.size(0)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred==y).sum().item()\n",
        "            total += y.size(0)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_pred.extend(pred.cpu().numpy())\n",
        "    acc = correct/total\n",
        "    return acc, loss_sum/total, np.array(y_true), np.array(y_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 15  \n",
        "best_acc = 0.0\n",
        "\n",
        "\n",
        "mlflow.set_experiment(f\"Tyre_Model_{DATASET_TYPE}\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "\n",
        "    mlflow.log_param(\"model\", \"resnet18_layer4_unfrozen\")\n",
        "    mlflow.log_param(\"epochs\", EPOCHS)\n",
        "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
        "    mlflow.log_param(\"lr_head\", LEARNING_RATE_HEAD)\n",
        "    mlflow.log_param(\"lr_body\", LEARNING_RATE_BODY)\n",
        "    mlflow.log_param(\"class_weights\", class_weights.cpu().numpy())\n",
        "\n",
        "    print(f\"--- Starting Training for {EPOCHS} epochs ---\")\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print(f\"------------Commencing Epoch {epoch}/{EPOCHS}------------\")\n",
        "        model.train()\n",
        "        train_loss_sum = 0.0 \n",
        "        for x,y in train_dl:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(x), y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            train_loss_sum += loss.item() * y.size(0) \n",
        "        \n",
        "        # Get epoch stats\n",
        "        epoch_train_loss = train_loss_sum / len(train_ds)\n",
        "        acc, vloss, y_true, y_pred = evaluate()\n",
        "        \n",
        "        print(f\"Epoch {epoch}/{EPOCHS}: train_loss={epoch_train_loss:.4f} val_loss={vloss:.4f} val_acc={acc:.4f}\")\n",
        "        \n",
        "\n",
        "        mlflow.log_metric(\"train_loss\", epoch_train_loss, step=epoch)\n",
        "        mlflow.log_metric(\"val_loss\", vloss, step=epoch)\n",
        "        mlflow.log_metric(\"val_acc\", acc, step=epoch)\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            print(f\"  ðŸŽ‰ New best model! Saving... (acc={acc:.4f})\")\n",
        "            save_path = f\"best_{DATASET_TYPE}.pt\"\n",
        "            torch.save({\"model\": model.state_dict(), \"classes\": train_ds.classes}, save_path)\n",
        "            \n",
        "            # --- Log best model & score ---\n",
        "            mlflow.pytorch.log_model(model, \"best_model\")\n",
        "            mlflow.log_metric(\"best_val_acc\", best_acc)\n",
        "    \n",
        "    print(f\"\\nâœ… Training complete. Best val_acc={best_acc:.4f}\")\n",
        "    \n",
        "\n",
        "    # Log classification report\n",
        "    report = classification_report(y_true, y_pred, target_names=train_ds.classes)\n",
        "    with open(\"classification_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    mlflow.log_artifact(\"classification_report.txt\")\n",
        "    \n",
        "    # Log confusion matrix\n",
        "    cm_plot = plt.figure()\n",
        "    plt.imshow(confusion_matrix(y_true, y_pred), interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix (Last Epoch)\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(train_ds.classes))\n",
        "    plt.xticks(tick_marks, train_ds.classes, rotation=45)\n",
        "    plt.yticks(tick_marks, train_ds.classes)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    cm_path = \"confusion_matrix.png\"\n",
        "    plt.savefig(cm_path)\n",
        "    mlflow.log_artifact(cm_path)\n",
        "    plt.close(cm_plot) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: y_true and y_pred are from the *last* epoch\n",
        "print(f\"\\nâœ… Training complete. Best val_acc={best_acc:.4f}\")\n",
        "print(\"--- Final Report (from last epoch) ---\")\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, target_names=train_ds.classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_for_roc():\n",
        "    model.eval()\n",
        "    y_true_all, y_pred_all = [], []\n",
        "    y_proba_all = [] # <-- NEW: Store probabilities\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x,y in val_dl:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            \n",
        "            # 1. Get Logits\n",
        "            logits = model(x)\n",
        "            \n",
        "            # 2. Get Probabilities\n",
        "            probas = F.softmax(logits, dim=1)\n",
        "            \n",
        "            # 3. Get Final Predictions\n",
        "            pred = logits.argmax(1)\n",
        "            \n",
        "            # --- Store everything ---\n",
        "            y_true_all.extend(y.cpu().numpy())\n",
        "            y_pred_all.extend(pred.cpu().numpy())\n",
        "            \n",
        "            # Store the probability of the POSITIVE class (class 1, \"worn\")\n",
        "            y_proba_all.extend(probas[:, 1].cpu().numpy()) \n",
        "\n",
        "    return np.array(y_true_all), np.array(y_pred_all), np.array(y_proba_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating ROC-AUC plot...\")\n",
        "\n",
        "# 1. Get the values from your (last) model\n",
        "y_true, y_pred, y_proba = evaluate_for_roc()\n",
        "\n",
        "# 2. Calculate the ROC curve points\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
        "\n",
        "# 3. Calculate the Area Under the Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(f\"\\nModel AUC Score: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
        "         label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title(f'Receiver Operating Characteristic (ROC) Curve - {DATASET_TYPE}')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "\n",
        "# --- NEW: Save plot as artifact ---\n",
        "plot_filename = f\"roc_auc_plot_{DATASET_TYPE}.png\"\n",
        "plt.savefig(plot_filename)\n",
        "print(f\"Saved ROC plot to {plot_filename}\")\n",
        "\n",
        "# If your MLFlow run is still active, you would log it:\n",
        "# mlflow.log_artifact(plot_filename)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
